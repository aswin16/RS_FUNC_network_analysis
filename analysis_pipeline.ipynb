{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oIvhc_R1D6k1"
   },
   "source": [
    "# Human Connectome Project (HCP) Dataset loader\n",
    "\n",
    "The HCP dataset comprises resting-state and task-based fMRI from a large sample of human subjects. The NMA-curated dataset includes time series data that has been preprocessed and spatially-downsampled by aggregating within 360 regions of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fXIw61Dk-M5E"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations, combinations_with_replacement\n",
    "from tqdm import tqdm, trange\n",
    "import rcca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "4eJOYQqgSMKV"
   },
   "outputs": [],
   "source": [
    "#@title Figure settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CSdEhS5jKzkb"
   },
   "source": [
    "# Basic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oL4crLoCzkzk"
   },
   "outputs": [],
   "source": [
    "# The download cells will store the data in nested directories starting here:\n",
    "HCP_DIR = \"../group_project/hcp\"\n",
    "if not os.path.isdir(HCP_DIR):\n",
    "  os.mkdir(HCP_DIR)\n",
    "\n",
    "# The data shared for NMA projects is a subset of the full HCP dataset\n",
    "N_SUBJECTS = 339\n",
    "\n",
    "# The data have already been aggregated into ROIs from the Glasesr parcellation\n",
    "N_PARCELS = 360\n",
    "\n",
    "# The acquisition parameters for all tasks were identical\n",
    "TR = 0.72  # Time resolution, in sec\n",
    "\n",
    "# The parcels are matched across hemispheres with the same order\n",
    "HEMIS = [\"Right\", \"Left\"]\n",
    "\n",
    "# Each experiment was repeated multiple times in each subject\n",
    "N_RUNS_REST = 4\n",
    "N_RUNS_TASK = 2\n",
    "\n",
    "# Time series data are organized by experiment, with each experiment\n",
    "# having an LR and RL (phase-encode direction) acquistion\n",
    "BOLD_NAMES = [\n",
    "  \"rfMRI_REST1_LR\", \"rfMRI_REST1_RL\",\n",
    "  \"rfMRI_REST2_LR\", \"rfMRI_REST2_RL\",\n",
    "  \"tfMRI_MOTOR_RL\", \"tfMRI_MOTOR_LR\",\n",
    "  \"tfMRI_WM_RL\", \"tfMRI_WM_LR\",\n",
    "  \"tfMRI_EMOTION_RL\", \"tfMRI_EMOTION_LR\",\n",
    "  \"tfMRI_GAMBLING_RL\", \"tfMRI_GAMBLING_LR\",\n",
    "  \"tfMRI_LANGUAGE_RL\", \"tfMRI_LANGUAGE_LR\",\n",
    "  \"tfMRI_RELATIONAL_RL\", \"tfMRI_RELATIONAL_LR\",\n",
    "  \"tfMRI_SOCIAL_RL\", \"tfMRI_SOCIAL_LR\"\n",
    "]\n",
    "\n",
    "# You may want to limit the subjects used during code development.\n",
    "# This will use all subjects:\n",
    "subjects = range(N_SUBJECTS)\n",
    "\n",
    "# for code development, we will first start using just one person's data\n",
    "# subjects = range(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HaF8v-UBTcxq"
   },
   "source": [
    "## Loading region information\n",
    "\n",
    "Downloading either dataset will create the `regions.npy` file, which contains the region name and network assignment for each parcel.\n",
    "\n",
    "Detailed information about the name used for each region is provided [in the Supplement](https://static-content.springer.com/esm/art%3A10.1038%2Fnature18933/MediaObjects/41586_2016_BFnature18933_MOESM330_ESM.pdf) to [Glasser et al. 2016](https://www.nature.com/articles/nature18933).\n",
    "\n",
    "Information about the network parcellation is provided in [Ji et al, 2019](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6289683/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "28q_GDlXOyMi"
   },
   "outputs": [],
   "source": [
    "regions = np.load(f\"{HCP_DIR}/regions.npy\").T\n",
    "region_info = dict(\n",
    "    name=regions[0].tolist(),\n",
    "    network=regions[1],\n",
    "    myelin=regions[2].astype(np.float),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NYDxvWrbIxxk"
   },
   "source": [
    "# Helper functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZDFPnQ07MmEd"
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pnq7H5h_IxLi"
   },
   "outputs": [],
   "source": [
    "def get_image_ids(name):\n",
    "  \"\"\"Get the 1-based image indices for runs in a given experiment.\n",
    "\n",
    "    Args:\n",
    "      name (str) : Name of experiment (\"rest\" or name of task) to load\n",
    "    Returns:\n",
    "      run_ids (list of int) : Numeric ID for experiment image files\n",
    "\n",
    "  \"\"\"\n",
    "  run_ids = [\n",
    "    i for i, code in enumerate(BOLD_NAMES, 1) if name.upper() in code\n",
    "  ]\n",
    "  if not run_ids:\n",
    "    raise ValueError(f\"Found no data for '{name}''\")\n",
    "  return run_ids\n",
    "\n",
    "def load_timeseries(subject, name, runs=None, concat=True, remove_mean=True):\n",
    "  \"\"\"Load timeseries data for a single subject.\n",
    "  \n",
    "  Args:\n",
    "    subject (int): 0-based subject ID to load\n",
    "    name (str) : Name of experiment (\"rest\" or name of task) to load\n",
    "    run (None or int or list of ints): 0-based run(s) of the task to load,\n",
    "      or None to load all runs.\n",
    "    concat (bool) : If True, concatenate multiple runs in time\n",
    "    remove_mean (bool) : If True, subtract the parcel-wise mean\n",
    "\n",
    "  Returns\n",
    "    ts (n_parcel x n_tp array): Array of BOLD data values\n",
    "\n",
    "  \"\"\"\n",
    "  # Get the list relative 0-based index of runs to use\n",
    "  if runs is None:\n",
    "    runs = range(N_RUNS_REST) if name == \"rest\" else range(N_RUNS_TASK)\n",
    "  elif isinstance(runs, int):\n",
    "    runs = [runs]\n",
    "\n",
    "  # Get the first (1-based) run id for this experiment \n",
    "  offset = get_image_ids(name)[0]\n",
    "\n",
    "  # Load each run's data\n",
    "  bold_data = [\n",
    "      load_single_timeseries(subject, offset + run, remove_mean) for run in runs\n",
    "  ]\n",
    "\n",
    "  # Optionally concatenate in time\n",
    "  if concat:\n",
    "    bold_data = np.concatenate(bold_data, axis=-1)\n",
    "\n",
    "  return bold_data\n",
    "\n",
    "\n",
    "def load_single_timeseries(subject, bold_run, remove_mean=True):\n",
    "  \"\"\"Load timeseries data for a single subject and single run.\n",
    "  \n",
    "  Args:\n",
    "    subject (int): 0-based subject ID to load\n",
    "    bold_run (int): 1-based run index, across all tasks\n",
    "    remove_mean (bool): If True, subtract the parcel-wise mean\n",
    "\n",
    "  Returns\n",
    "    ts (n_parcel x n_timepoint array): Array of BOLD data values\n",
    "\n",
    "  \"\"\"\n",
    "  bold_path = f\"{HCP_DIR}/subjects/{subject}/timeseries\"\n",
    "  bold_file = f\"bold{bold_run}_Atlas_MSMAll_Glasser360Cortical.npy\"\n",
    "  ts = np.load(f\"{bold_path}/{bold_file}\")\n",
    "  if remove_mean:\n",
    "    ts -= ts.mean(axis=1, keepdims=True)\n",
    "  return ts\n",
    "\n",
    "def load_evs(subject, name, condition):\n",
    "  \"\"\"Load EV (explanatory variable) data for one task condition.\n",
    "\n",
    "  Args:\n",
    "    subject (int): 0-based subject ID to load\n",
    "    name (str) : Name of task\n",
    "    condition (str) : Name of condition\n",
    "\n",
    "  Returns\n",
    "    evs (list of dicts): A dictionary with the onset, duration, and amplitude\n",
    "      of the condition for each run.\n",
    "\n",
    "  \"\"\"\n",
    "  evs = []\n",
    "  for id in get_image_ids(name):\n",
    "    task_key = BOLD_NAMES[id - 1]\n",
    "    ev_file = f\"{HCP_DIR}/subjects/{subject}/EVs/{task_key}/{condition}.txt\"\n",
    "    ev_array = np.loadtxt(ev_file, ndmin=2, unpack=True)\n",
    "    ev = dict(zip([\"onset\", \"duration\", \"amplitude\"], ev_array))\n",
    "    evs.append(ev)\n",
    "  return evs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qQzCA99sMryW"
   },
   "source": [
    "## Task-based analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HgnEuN0gMqxP"
   },
   "outputs": [],
   "source": [
    "def condition_frames(run_evs, skip=0):\n",
    "  \"\"\"Identify timepoints corresponding to a given condition in each run.\n",
    "\n",
    "  Args:\n",
    "    run_evs (list of dicts) : Onset and duration of the event, per run\n",
    "    skip (int) : Ignore this many frames at the start of each trial, to account\n",
    "      for hemodynamic lag\n",
    "\n",
    "  Returns:\n",
    "    frames_list (list of 1D arrays): Flat arrays of frame indices, per run\n",
    "\n",
    "  \"\"\"\n",
    "  frames_list = []\n",
    "  for ev in run_evs:\n",
    "\n",
    "    # Determine when trial starts, rounded down\n",
    "    start = np.floor(ev[\"onset\"] / TR).astype(int)\n",
    "\n",
    "    # Use trial duration to determine how many frames to include for trial\n",
    "    duration = np.ceil(ev[\"duration\"] / TR).astype(int)\n",
    "\n",
    "    # Take the range of frames that correspond to this specific trial\n",
    "    frames = [s + np.arange(skip, d) for s, d in zip(start, duration)]\n",
    "\n",
    "    frames_list.append(np.concatenate(frames))\n",
    "\n",
    "  return frames_list\n",
    "\n",
    "\n",
    "def selective_average(timeseries_data, ev, skip=0):\n",
    "  \"\"\"Take the temporal mean across frames for a given condition.\n",
    "\n",
    "  Args:\n",
    "    timeseries_data (array or list of arrays): n_parcel x n_tp arrays\n",
    "    ev (dict or list of dicts): Condition timing information\n",
    "    skip (int) : Ignore this many frames at the start of each trial, to account\n",
    "      for hemodynamic lag\n",
    "\n",
    "  Returns:\n",
    "    avg_data (1D array): Data averagted across selected image frames based\n",
    "    on condition timing\n",
    "\n",
    "  \"\"\"\n",
    "  # Ensure that we have lists of the same length\n",
    "  if not isinstance(timeseries_data, list):\n",
    "    timeseries_data = [timeseries_data]\n",
    "  if not isinstance(ev, list):\n",
    "    ev = [ev]\n",
    "  if len(timeseries_data) != len(ev):\n",
    "    raise ValueError(\"Length of `timeseries_data` and `ev` must match.\")\n",
    "\n",
    "  # Identify the indices of relevant frames\n",
    "  frames = condition_frames(ev, skip)\n",
    "\n",
    "  # Select the frames from each image\n",
    "  selected_data = []\n",
    "  for run_data, run_frames in zip(timeseries_data, frames):\n",
    "    run_frames = run_frames[run_frames < run_data.shape[1]]\n",
    "    selected_data.append(run_data[:, run_frames])\n",
    "\n",
    "  # Take the average in each parcel\n",
    "  avg_data = np.concatenate(selected_data, axis=-1).mean(axis=-1)\n",
    "\n",
    "  return avg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RKOzUn2iPnQL"
   },
   "source": [
    "# Task analyses\n",
    "\n",
    "Description of each task, task timing, and conditions is located [here](https://protocols.humanconnectome.org/HCP/3T/task-fMRI-protocol-details.html).\n",
    "\n",
    "These are the condition names for each task:\n",
    "\n",
    "```\n",
    "- MOTOR: cue, lf, lh, rf, rh, t\n",
    "- WM:\n",
    "    0bk_body, 0bk_faces, 0bk_nir, 0bk_placed, 0bk_tools, \n",
    "    2bk_body, 2bk_faces, 2bk_nir, 2bk_placed, 2bk_tools,\n",
    "    0bk_cor, 0bk_err,\n",
    "    2bk_cor, 2bk_err,\n",
    "    all_bk_cor, all_bk_err\n",
    "- EMOTION: fear, neut\n",
    "- GAMBLING: loss, loss_event, win, win_event, neut_event\n",
    "- LANGUAGE:\n",
    "    cue,\n",
    "    math, story\n",
    "    present_math, present_story,\n",
    "    question_math, question_story,\n",
    "    response_math, response_story\n",
    "- RELATIONAL: error, match, relation\n",
    "- SOCIAL: mental_resp, mental, other_resp, rnd\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cacluate Task-wise functional connectivity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selective_fc_mat(timeseries_data, ev, combs, skip=0, level=\"network\"):\n",
    "  \"\"\"Take the temporal mean across frames for a given condition.\n",
    "\n",
    "  Args:\n",
    "    timeseries_data (array or list of arrays): n_parcel x n_tp arrays\n",
    "    ev (dict or list of dicts): Condition timing information\n",
    "    skip (int) : Ignore this many frames at the start of each trial, to account\n",
    "      for hemodynamic lag\n",
    "    level (str) : to which level will it reduce the data. either 'parcel' or 'network'\n",
    "\n",
    "  Returns:\n",
    "    avg_data (1D array): Data averagted across selected image frames based\n",
    "    on condition timing\n",
    "\n",
    "  \"\"\"\n",
    "  # Ensure that we have lists of the same length\n",
    "  if not isinstance(timeseries_data, list):\n",
    "    timeseries_data = [timeseries_data]\n",
    "  if not isinstance(ev, list):\n",
    "    ev = [ev]\n",
    "  if len(timeseries_data) != len(ev):\n",
    "    raise ValueError(\"Length of `timeseries_data` and `ev` must match.\")\n",
    "  if level not in [\"network\", \"parcels\"]:\n",
    "    raise ValueError(\"level needs to be either `network` or `parcels`.\")\n",
    "  \n",
    "  # Identify the indices of relevant frames\n",
    "  frames = condition_frames(ev, skip)\n",
    "  # Select the frames from each image\n",
    "  selected_data = []\n",
    "  # test_data = []\n",
    "  for run_data, run_frames in zip(timeseries_data, frames):\n",
    "    run_frames = run_frames[run_frames < run_data.shape[1]]\n",
    "    selected_data.append(run_data[:, run_frames])\n",
    "  # reduce the dimension\n",
    "  # reduced_data = np.array(selected_data) # np.array(selected_data).reshape(360, len(frames) * len(run_frames)) \n",
    "  for i in range(len(selected_data)):\n",
    "    if i == 0:\n",
    "      tmp_data = np.array(selected_data[0])\n",
    "    else:\n",
    "      tmp_data = np.hstack((tmp_data, np.array(selected_data[i])))\n",
    "  reduced_data = tmp_data\n",
    "\n",
    "  # calculate the functional connectivity map\n",
    "  fc_data = np.corrcoef(reduced_data)\n",
    "  # connectivity between parcel 1 and parcel 4 would be fc_data[0,3] or fc_data[3,0]\n",
    "    \n",
    "  # calculate mean connectivity between different network  \n",
    "  if level == \"network\":\n",
    "    result = []\n",
    "    for net1, net2 in combs:\n",
    "      net1_parcels = [i for i,v in enumerate(network) if v == net1] # network: a list of lenght 360\n",
    "      net2_parcels = [i for i,v in enumerate(network) if v == net2]\n",
    "      result.append(np.mean(fc_data[np.ix_(net1_parcels,net2_parcels)]))\n",
    "  elif level == \"parcels\":\n",
    "    result = fc_data\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_cond = {\n",
    "  \"motor\": [\"lf\", \"rf\", \"lh\", \"rh\", \"t\"],\n",
    "  \"wm\": [\"0bk_body\", \"0bk_faces\", \"0bk_places\", \"0bk_tools\", \n",
    "         \"2bk_body\", \"2bk_faces\", \"2bk_places\", \"2bk_tools\"],\n",
    "  \"emotion\": [\"fear\", \"neut\"],\n",
    "  \"gambling\": [\"win\", \"loss\"],\n",
    "  \"language\": [\"story\", \"math\"],\n",
    "  \"relational\": [\"relation\", \"match\"],\n",
    "  \"social\": [\"mental\", \"rnd\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [01:54<00:00,  2.97it/s]\n"
     ]
    }
   ],
   "source": [
    "network_fc_all = {}\n",
    "network = region_info[\"network\"]\n",
    "network_names = np.unique(network)\n",
    "combs = list(combinations_with_replacement(network_names, 2))\n",
    "\n",
    "for subject in tqdm(subjects):\n",
    "  # timeseries_all[subject] = {}\n",
    "  for task, conditions in task_cond.items():\n",
    "    if subject == 0:\n",
    "      network_fc_all[task] = {}\n",
    "    tmp_timeseries = load_timeseries(subject, task, concat=False)\n",
    "    for cond in conditions:\n",
    "      # initialize for first subject\n",
    "      if subject == 0:\n",
    "        network_fc_all[task][cond] = np.zeros((len(subjects), len(combs)))\n",
    "      ev = load_evs(subject, task, cond)\n",
    "      network_fc_all[task][cond][subject,:] = selective_fc_mat(tmp_timeseries, ev, combs, skip=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data into pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('network_summary.dat', 'wb') as f:\n",
    "    pickle.dump(network_fc_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('network_summary.dat', 'rb') as f:\n",
    "    new_dat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['motor', 'wm', 'emotion', 'gambling', 'language', 'relational', 'social'])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dat.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Resting-state Functional Connectivity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [00:09<00:00, 35.71it/s]\n"
     ]
    }
   ],
   "source": [
    "network = region_info[\"network\"]\n",
    "network_names = np.unique(network)\n",
    "combs = list(combinations_with_replacement(network_names, 2))\n",
    "\n",
    "rest_network = []\n",
    "\n",
    "for subject in tqdm(subjects):\n",
    "  ts_concat = load_timeseries(subject, \"rest\")\n",
    "  fc_rest = np.corrcoef(ts_concat)\n",
    "  result = []\n",
    "  for net1, net2 in combs:\n",
    "    net1_parcels = [i for i,v in enumerate(network) if v == net1]\n",
    "    net2_parcels = [i for i,v in enumerate(network) if v == net2]\n",
    "    result.append(np.mean(fc_rest[np.ix_(net1_parcels,net2_parcels)]))\n",
    "  rest_network.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rest_network to a numpy array\n",
    "rest_network = np.array(rest_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "cca = CCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339, 78)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data preparation\n",
    "X = rest_network\n",
    "Y = network_fc_all['language']['math']\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CCA(copy=True, max_iter=500, n_components=2, scale=True, tol=1e-06)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cca.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply dimension reduction technique -> subject x n_components\n",
    "X_r, Y_r = cca.transform(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339, 2)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_r.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Pyrcca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rcca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca = rcca.CCA(kernelcca = False, reg = 0., numCC = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = rest_network[:len(subjects)//2]\n",
    "Y_train = network_fc_all['language']['math'][:len(subjects)//2]\n",
    "X_test  = rest_network[len(subjects)//2:]\n",
    "Y_test  = network_fc_all['language']['math'][len(subjects)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CCA, kernel = None, regularization = 0.0000, 2 components\n",
      "Computing explained variance for component #1\n",
      "Computing explained variance for component #2\n"
     ]
    }
   ],
   "source": [
    "cca.train([X_train, Y_train])\n",
    "corrs = cca.validate([X_test, Y_test])\n",
    "ev = cca.compute_ev([X_test, Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 156)\n"
     ]
    }
   ],
   "source": [
    "# data preparation\n",
    "X = rest_network # n_subject x connectivity measures (78 = 66 (12C2) + 12)\n",
    "Y = np.hstack((network_fc_all['emotion']['neut'], network_fc_all['emotion']['fear']))\n",
    "print(Y.shape)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=True, with_std=True)\n",
    "X_sc = sc.fit_transform(X)\n",
    "Y_sc = sc.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CCA, kernel = None, regularization = 0.1000, 5 components\n",
      "Canonical Correlation Per Component Pair: [0.95094805 0.94087171 0.93515026 0.93541459 0.9314675 ]\n",
      "% Shared Variance: [0.9043022  0.88523957 0.87450601 0.87500045 0.8676317 ]\n"
     ]
    }
   ],
   "source": [
    "cca = rcca.CCA(kernelcca = False, reg = 1e-1, numCC = 5)\n",
    "cca.train([X_sc, Y_sc])\n",
    "print('Canonical Correlation Per Component Pair:',cca.cancorrs)\n",
    "print('% Shared Variance:',cca.cancorrs**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canonical Correlation Per Component Pair: [0.48340104 0.13304219 0.14352808 0.1332709  0.26647726 0.23268404\n",
      " 0.22725339 0.1985611 ]\n",
      "% Shared Variance: [0.23367656 0.01770022 0.02060031 0.01776113 0.07101013 0.05414186\n",
      " 0.0516441  0.03942651]\n"
     ]
    }
   ],
   "source": [
    "cca = rcca.CCACrossValidate(regs=[1e-1, 1, 1e2, 1e3, 1e4, 1e5], numCCs=[2, 3, 4, 5, 6, 7, 8, 9])\n",
    "cca.train([X_sc, Y_sc])\n",
    "print('Canonical Correlation Per Component Pair:',cca.cancorrs)\n",
    "print('% Shared Variance:',cca.cancorrs**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of components: 8 \n",
      "Optimal regularization coefficient: 100000.000000\n"
     ]
    }
   ],
   "source": [
    "print(f'Optimal number of components: {cca.best_numCC} \\nOptimal regularization coefficient: {cca.best_reg:f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, prepare the FC map for the functional data, which takes up around 8 gigs of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [00:16<00:00, 20.50it/s]\n"
     ]
    }
   ],
   "source": [
    "network_fc_parcels = {}\n",
    "\n",
    "for subject in tqdm(subjects):\n",
    "  for task, conditions in task_cond.items():\n",
    "    # initialize for first subject\n",
    "    if subject == 0:\n",
    "      network_fc_parcels[task] = {}\n",
    "    tmp_timeseries = load_timeseries(subject, task, concat=False)\n",
    "    for cond in conditions:\n",
    "      # initialize for first subject\n",
    "      if subject == 0:\n",
    "        network_fc_parcels[task][cond] = []\n",
    "      ev = load_evs(subject, task, cond)\n",
    "      network_fc_parcels[task][cond].append(selective_fc_mat(tmp_timeseries, ev, combs, skip=0, level = \"parcels\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then, prepare FC map for the rest data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [00:05<00:00, 65.13it/s]\n"
     ]
    }
   ],
   "source": [
    "network_rest_parcels = []\n",
    "\n",
    "for subject in tqdm(subjects):\n",
    "  ts_concat = load_timeseries(subject, \"rest\")\n",
    "  fc_rest = np.corrcoef(ts_concat)\n",
    "  network_rest_parcels.append(fc_rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, preprocess the data and perform CCA every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "permut_iter = 5000\n",
    "network = region_info[\"network\"]\n",
    "network_names = np.unique(network)\n",
    "combs = list(combinations_with_replacement(network_names, 2))\n",
    "designate_task = \"language\"\n",
    "\n",
    "# create pre_defined random network set\n",
    "random_networks = []\n",
    "for _ in range(permut_iter):\n",
    "  np.random.shuffle(network)\n",
    "  random_networks.append(network.copy())\n",
    "# to save results\n",
    "permut_rsq = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 108/5000 [10:00<7:27:48,  5.49s/it]"
     ]
    }
   ],
   "source": [
    "for i in trange(permut_iter):\n",
    "  \n",
    "  ##########################################\n",
    "  ############# Preprocessing ##############\n",
    "  ##########################################\n",
    "  # randomly shuffle network every iteration\n",
    "  tmp_network = random_networks[i]\n",
    "  \n",
    "  # data preprocessing part per subject\n",
    "  X_rest = np.zeros((len(subjects), len(combs)))\n",
    "  Y_tmp = {}\n",
    "  for subj in subjects:\n",
    "    # preprocess the resting data\n",
    "    for j, nets in enumerate(combs):\n",
    "      net1_parcels = [i for i,v in enumerate(tmp_network) if v == nets[0]]\n",
    "      net2_parcels = [i for i,v in enumerate(tmp_network) if v == nets[1]]\n",
    "      X_rest[subj,j] = np.mean(network_rest_parcels[subj][np.ix_(net1_parcels,net2_parcels)])\n",
    "        \n",
    "      # preprocess the functional data\n",
    "      for cond in task_cond[designate_task]:\n",
    "        if subj == 0:\n",
    "          Y_tmp[cond] = np.zeros((len(subjects), len(combs)))\n",
    "        Y_tmp[cond][subj,j] = np.mean(network_fc_parcels[designate_task][cond][subj][np.ix_(net1_parcels,net2_parcels)])\n",
    "  \n",
    "  for i, cond in enumerate(Y_tmp.keys()):\n",
    "    if i == 0:\n",
    "      Y_task = Y_tmp[cond]\n",
    "    else:\n",
    "      Y_task = np.hstack((Y_task, Y_tmp[cond]))\n",
    "      \n",
    "  ##########################################\n",
    "  #############      CCA      ##############\n",
    "  ##########################################\n",
    "  cca = rcca.CCA(kernelcca = False, reg = 0., numCC = 5, verbose=False)\n",
    "  cca.train([X_rest, Y_task])\n",
    "  permut_rsq.append(cca.cancorrs**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = np.array(permut_rsq)\n",
    "np.save('permutation_shared_variances', final_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ZDFPnQ07MmEd",
    "qQzCA99sMryW"
   ],
   "include_colab_link": true,
   "name": "load_hcp.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "neuro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
